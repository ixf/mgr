{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sys import argv\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, concatenate, Embedding\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from keras.utils import to_categorical\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning\n",
    "params = {\n",
    "    'activation': ['relu', 'elu', 'sigmoid'],\n",
    "    'batch_size': [100],\n",
    "    'epochs': [20],\n",
    "    'lr': [0.01, 0.04],\n",
    "    'momentum': [0.95],\n",
    "    'hidden_neurons': [100, 200, 400, 800, 1200],\n",
    "    'loss': ['mean_squared_logarithmic_error', 'huber', 'mean_absolute_percentage_error', 'mean_absolute_error', 'mean_squared_error']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_COUNT = 10\n",
    "WINDOW_SIZES = (16, 3)\n",
    "LOOKAHEAD = 1\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "KB = 1024\n",
    "LONG_JUMP_THRESHOLD = 256 * KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "df = read_csv('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(source):\n",
    "    global d\n",
    "    # Input loading and preprocessing:\n",
    "    # - load data and get the read locations\n",
    "    # - convert into samples by sliding a window\n",
    "    # - prepare decoder input\n",
    "    # - split into input and output\n",
    "\n",
    "    with open(source) as f:\n",
    "        data = json.loads(f.read())\n",
    "\n",
    "    filereads = defaultdict(list)\n",
    "\n",
    "    for op in data[\"operations\"]:\n",
    "        if op[\"type\"] != \"read\":\n",
    "            continue\n",
    "\n",
    "        path, loc, size = op[\"path\"], op[\"offset\"], op[\"size\"]\n",
    "        filereads[path].append((loc, size))\n",
    "\n",
    "    some_file = list(filereads.keys())[0]\n",
    "    x = np.array(filereads[some_file])\n",
    "    ins, outs = [], []\n",
    "\n",
    "    # Split reads into samples:\n",
    "    for i in range(len(x) - WINDOW_SIZES[0] - WINDOW_SIZES[1] + 1):\n",
    "        # NOTE: just offset, not size\n",
    "        ins.append(x[i:(i+WINDOW_SIZES[0]), :1].tolist())\n",
    "        outs.append(x[(i+WINDOW_SIZES[0]):(i+WINDOW_SIZES[0]+WINDOW_SIZES[1]), :1].tolist())\n",
    "        \n",
    "    # shuffle\n",
    "    io = [np.array(ins), np.array(outs)]\n",
    "    io = np.concatenate(io, axis=1)\n",
    "    # shuffles along the first axis\n",
    "    np.random.shuffle(io)\n",
    "    # recover\n",
    "    ins = io[:, :WINDOW_SIZES[0], 0]\n",
    "    outs = io[:, WINDOW_SIZES[0]:, 0]\n",
    "    \n",
    "    # convert ins to ins and outs to jumps\n",
    "    def make_rel(w):\n",
    "        rels = w[:, 1:] - w[:, :-1]\n",
    "        return rels\n",
    "    \n",
    "    print(ins.shape)\n",
    "    ins = make_rel(ins)\n",
    "    outs = make_rel(outs)\n",
    "    \n",
    "    # remove uncommon jumps\n",
    "    from collections import Counter\n",
    "    ic = Counter(ins.reshape((-1)))\n",
    "    ic = ic.most_common(96)\n",
    "    ins2 = np.zeros(ins.shape)\n",
    "    ins2[:, :] = 0.2\n",
    "    outs2 = np.zeros(outs.shape)\n",
    "    outs2[:, :] = 0.2\n",
    "    \n",
    "    # restore common jumps to ins2 and outs2:\n",
    "    ic = [v for v, _ in ic]\n",
    "    ic = {v: i for i, v in enumerate(ic)}\n",
    "    d = ic\n",
    "    for v, i in ic.items():\n",
    "        ins2[ins == v] = i\n",
    "        outs2[outs == v] = i\n",
    "    ins = ins2\n",
    "    outs = outs2\n",
    "    \n",
    "    # prepare decoder target\n",
    "    out_dec = np.roll(outs, -LOOKAHEAD, axis=1)\n",
    "    out_dec = out_dec[:, :-1]# = WINDOW_SIZES[0]+1\n",
    "    in_dec = outs[:, :-1]\n",
    "    \n",
    "    in_enc = to_categorical(ins)\n",
    "    in_dec = to_categorical(in_dec)\n",
    "    out_dec = to_categorical(out_dec)\n",
    "    \n",
    "    tkns = in_enc.shape[-1]\n",
    "    in_dec = in_dec.reshape((in_dec.shape[0], 1, in_dec.shape[-1]))\n",
    "    out_dec = out_dec.reshape((out_dec.shape[0], 1, out_dec.shape[-1]))\n",
    "\n",
    "    # Train/test split\n",
    "    j = int(len(ins)*TRAIN_TEST_SPLIT)\n",
    "    X_train = {'enc': in_enc[:j], 'dec': in_dec[:j]}\n",
    "    Y_train = out_dec[:j]\n",
    "    X_test = {'enc': in_enc[j:], 'dec': in_dec[j:]}\n",
    "    Y_test = out_dec[j:]\n",
    "\n",
    "    return (X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4078, 16)\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(data_filename)\n",
    "X_train, Y_train, X_test, Y_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07058c8f507d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'enc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'enc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train['enc'].shape)\n",
    "print(X_train['dec'].shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test['enc'].shape)\n",
    "print(X_test['dec'].shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(3262, 0, 96), dtype=bool)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['dec'][:, :-1] == Y_train[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### stara wersja create model poniej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_old(X_train, Y_train, params):\n",
    "    n_hidden = params['hidden_neurons']\n",
    "    token_count = X_train['enc'].shape[-1]\n",
    "\n",
    "    n_timesteps, n_features, n_outputs = X_train['abs'].shape[1], X_train['abs'].shape[2], Y_train.shape[1]\n",
    "    # n_features == 1\n",
    "\n",
    "    rel_input = Input(shape=(n_timesteps), name='abs')\n",
    "    emb_input = Embedding(token_count, 16)(rel_input)\n",
    "    lstm_in = LSTM(rel_input.shape[1])(emb_input)\n",
    "        \n",
    "    rel_input = Input(shape=(n_timesteps, n_features), name='abs')\n",
    "    lstm_in = LSTM(rel_input.shape[1])(rel_input)\n",
    "\n",
    "    abs_input = Input(shape=(n_timesteps), name='rel')\n",
    "    \n",
    "    lstm_in = LSTM(16)(emb_input)\n",
    "    dense_in = Dense(abs_input.shape[1])(abs_input)\n",
    "\n",
    "    concatenated = concatenate([lstm_in, dense_in], axis=-1)\n",
    "    rv = RepeatVector(Y_train.shape[1])(concatenated)\n",
    "    lstm_out = LSTM(n_hidden, return_sequences=True)(rv)\n",
    "    td_wrapped = TimeDistributed(Dense(Y_train.shape[2], activation=params['activation']))(lstm_in)\n",
    "\n",
    "    model = Model({'rel': rel_input, 'abs': abs_input}, td_wrapped)\n",
    "    \n",
    "    opt = SGD(lr=params['lr'], momentum=params['momentum'])\n",
    "    model.compile(optimizer='rmsprop', loss=params['loss'], metrics=['mape', 'acc'])\n",
    "    return model\n",
    "\n",
    "def seq2seq_model(X_train, Y_train, X_test, Y_test, params, verbose=0):\n",
    "\n",
    "    model = create_model(X_train, Y_train, params)\n",
    "    \n",
    "    if verbose != 0:\n",
    "        model.summary()\n",
    "    \n",
    "    out = model.fit(X_train, Y_train,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        epochs=params['epochs'],\n",
    "        verbose=verbose,\n",
    "        batch_size=params['batch_size'])\n",
    "    return out, model\n",
    "\n",
    "def load():\n",
    "    global model\n",
    "    model = load_model(MODEL_LOCATION)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### nowe create model poniej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, Y_train, params):\n",
    "    token_count = X_train['enc'].shape[-1]\n",
    "    latent_dim = params['hidden_neurons']\n",
    "    \n",
    "    enc_input = Input(shape=(None, token_count), name='enc')\n",
    "    _, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_input)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    dec_input = Input(shape=(None, token_count), name='dec')\n",
    "    decoder_outputs, _, _ = LSTM(latent_dim, return_sequences=True, return_state=True)(dec_input,\n",
    "                                     initial_state=encoder_states)\n",
    "    \n",
    "    decoder_dense = Dense(token_count, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model({'enc': enc_input, 'dec': dec_input}, decoder_outputs)\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss=params['loss'], metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def seq2seq_model(X_train, Y_train, X_test, Y_test, params, verbose=0):\n",
    "\n",
    "    model = create_model(X_train, Y_train, params)\n",
    "    \n",
    "    if verbose != 0:\n",
    "        model.summary()\n",
    "    \n",
    "    out = model.fit(X_train, Y_train,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        epochs=params['epochs'],\n",
    "        verbose=verbose,\n",
    "        batch_size=params['batch_size'])\n",
    "    return out, model\n",
    "\n",
    "def load():\n",
    "    global model\n",
    "    model = load_model(MODEL_LOCATION)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softmax',\n",
       " 'batch_size': 100,\n",
       " 'epochs': 25,\n",
       " 'lr': 0.01,\n",
       " 'momentum': 0.95,\n",
       " 'hidden_neurons': 400,\n",
       " 'loss': 'categorical_crossentropy'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'activation': ['softmax'],\n",
    "    'batch_size': [100],\n",
    "    'epochs': [25],\n",
    "    'lr': [0.01],\n",
    "    'momentum': [0.95],\n",
    "    'hidden_neurons': [400],\n",
    "    'loss': ['categorical_crossentropy']\n",
    "}\n",
    "anyparams = { k: random.choice(v) for k, v in params.items() }\n",
    "anyparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4078, 16)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc (InputLayer)                [(None, None, 96)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec (InputLayer)                [(None, None, 96)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 400), (None, 795200      enc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 400),  795200      dec[0][0]                        \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 96)     38496       lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,628,896\n",
      "Trainable params: 1,628,896\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/25\n",
      "33/33 [==============================] - 6s 101ms/step - loss: 3.7314 - accuracy: 0.2045 - val_loss: 3.1905 - val_accuracy: 0.2561\n",
      "Epoch 2/25\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 3.1273 - accuracy: 0.2371 - val_loss: 3.1162 - val_accuracy: 0.2561\n",
      "Epoch 3/25\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 3.0792 - accuracy: 0.2474 - val_loss: 3.1487 - val_accuracy: 0.2561\n",
      "Epoch 4/25\n",
      "33/33 [==============================] - 3s 89ms/step - loss: 3.0703 - accuracy: 0.2446 - val_loss: 3.1668 - val_accuracy: 0.2561\n",
      "Epoch 5/25\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 3.0630 - accuracy: 0.2386 - val_loss: 3.1869 - val_accuracy: 0.2549\n",
      "Epoch 6/25\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 3.0217 - accuracy: 0.2445 - val_loss: 3.1127 - val_accuracy: 0.2586\n",
      "Epoch 7/25\n",
      "33/33 [==============================] - 3s 100ms/step - loss: 2.9755 - accuracy: 0.2429 - val_loss: 3.0418 - val_accuracy: 0.2549\n",
      "Epoch 8/25\n",
      "33/33 [==============================] - 3s 104ms/step - loss: 2.9249 - accuracy: 0.2458 - val_loss: 3.0820 - val_accuracy: 0.2426\n",
      "Epoch 9/25\n",
      "33/33 [==============================] - 4s 125ms/step - loss: 2.8682 - accuracy: 0.2633 - val_loss: 3.0615 - val_accuracy: 0.2402\n",
      "Epoch 10/25\n",
      "33/33 [==============================] - 4s 126ms/step - loss: 2.8397 - accuracy: 0.2479 - val_loss: 3.0444 - val_accuracy: 0.2610\n",
      "Epoch 11/25\n",
      "33/33 [==============================] - 4s 131ms/step - loss: 2.8058 - accuracy: 0.2512 - val_loss: 3.0195 - val_accuracy: 0.2647\n",
      "Epoch 12/25\n",
      "33/33 [==============================] - 4s 116ms/step - loss: 2.7419 - accuracy: 0.2653 - val_loss: 3.0202 - val_accuracy: 0.2304\n",
      "Epoch 13/25\n",
      "33/33 [==============================] - 4s 115ms/step - loss: 2.6877 - accuracy: 0.2671 - val_loss: 3.0113 - val_accuracy: 0.2488\n",
      "Epoch 14/25\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 2.6542 - accuracy: 0.2739 - val_loss: 3.0351 - val_accuracy: 0.2500\n",
      "Epoch 15/25\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 2.6252 - accuracy: 0.2820 - val_loss: 3.0227 - val_accuracy: 0.2328\n",
      "Epoch 16/25\n",
      "33/33 [==============================] - 3s 94ms/step - loss: 2.5806 - accuracy: 0.2676 - val_loss: 3.0590 - val_accuracy: 0.2255\n",
      "Epoch 17/25\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 2.5304 - accuracy: 0.2936 - val_loss: 3.0901 - val_accuracy: 0.2377\n",
      "Epoch 18/25\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 2.4681 - accuracy: 0.2962 - val_loss: 3.0626 - val_accuracy: 0.2169\n",
      "Epoch 19/25\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 2.4274 - accuracy: 0.3113 - val_loss: 3.0918 - val_accuracy: 0.2194\n",
      "Epoch 20/25\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 2.4213 - accuracy: 0.2892 - val_loss: 3.1592 - val_accuracy: 0.2549\n",
      "Epoch 21/25\n",
      "33/33 [==============================] - 3s 101ms/step - loss: 2.3390 - accuracy: 0.3250 - val_loss: 3.2696 - val_accuracy: 0.2353\n",
      "Epoch 22/25\n",
      "33/33 [==============================] - 4s 107ms/step - loss: 2.2810 - accuracy: 0.3421 - val_loss: 3.2529 - val_accuracy: 0.2341\n",
      "Epoch 23/25\n",
      "33/33 [==============================] - 3s 101ms/step - loss: 2.2441 - accuracy: 0.3398 - val_loss: 3.2388 - val_accuracy: 0.2267\n",
      "Epoch 24/25\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 2.1749 - accuracy: 0.3558 - val_loss: 3.4166 - val_accuracy: 0.2243\n",
      "Epoch 25/25\n",
      "33/33 [==============================] - 3s 93ms/step - loss: 2.0916 - accuracy: 0.3691 - val_loss: 3.3744 - val_accuracy: 0.1973\n"
     ]
    }
   ],
   "source": [
    "# dbg train\n",
    "data = prepare_data(data_filename)\n",
    "X_train, Y_train, X_test, Y_test = data\n",
    "fit, model = seq2seq_model(X_train, Y_train, X_test, Y_test, anyparams, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19730392156862744"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model, data):\n",
    "    X_train, Y_train, X_test, Y_test = data\n",
    "\n",
    "    q = model.predict(X_test)\n",
    "    return np.mean(np.argmax(q[:, :, :], axis=-1) == np.argmax(Y_test[:, :, :], axis=-1))\n",
    "test(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: 0.1973039209842682\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=128, verbose=0)\n",
    "print(\"test loss, test acc:\", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data_filename.split('/')[-1].split('.')[0]\n",
    "f\n",
    "model.save(\"saved/xd\" + f + \".h5\")\n",
    "with open(\"saved/xd\" + f + '.pickle', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for opens in [64, 256, 1024]:\n",
    "    for seqlen in [8, 16, 24]:\n",
    "        for seqcount in [16, 64, 256]:\n",
    "            f = f\"../../patterns/sequences_{opens}_{seqlen}_{seqcount}.json\"\n",
    "            files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../patterns/sequences_64_8_16.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1db97b5bd9c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manyparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-876a3764df59>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# - split into input and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../patterns/sequences_64_8_16.json'"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    X_train, Y_train, X_test, Y_test = prepare_data(f)\n",
    "    fit, model = seq2seq_model(X_train, Y_train, X_test, Y_test, anyparams, verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test, batch_size=128, verbose=0)\n",
    "    print(f)\n",
    "    print(\"acc:\", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softmax',\n",
       " 'batch_size': 200,\n",
       " 'epochs': 20,\n",
       " 'lr': 0.02,\n",
       " 'momentum': 0.95,\n",
       " 'hidden_neurons': 400,\n",
       " 'loss': 'categorical_crossentropy'}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'activation': ['softmax'],\n",
    "    'batch_size': [200],\n",
    "    'epochs': [20],\n",
    "    'lr': [0.02],\n",
    "    'momentum': [0.95],\n",
    "    'hidden_neurons': [400],\n",
    "    'loss': ['categorical_crossentropy']\n",
    "}\n",
    "anyparams = { k: random.choice(v) for k, v in params.items() }\n",
    "anyparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(pattern):\n",
    "    data = prepare_data(pattern)\n",
    "    X_train, Y_train, X_test, Y_test = data\n",
    "    fit, model = seq2seq_model(X_train, Y_train, X_test, Y_test, anyparams, verbose=0)\n",
    "    \n",
    "    result = test(model, data)\n",
    "    \n",
    "    f = pattern.split('/')[-1].split('.')[0]\n",
    "    model.save(\"saved/\" + f + \".h5\")\n",
    "    with open(\"saved/\" + f + '.pickle', 'wb') as f:\n",
    "        pickle.dump(d, f)\n",
    "    \n",
    "    print(pattern, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = \"\"\"\n",
    "sequences_64_24_64\n",
    "sequences_256_24_64\n",
    "\"\"\".split()\n",
    "\n",
    "\"\"\"\n",
    "sequences_64_24_64\n",
    "sequences_256_24_64\n",
    "\n",
    "\n",
    "sequences_1024_8_16\n",
    "\n",
    "sequences_1024_16_64\n",
    "sequences_1024_24_256\n",
    "\n",
    "sequences_64_8_16\n",
    "sequences_64_16_64\n",
    "sequences_64_24_256\n",
    "\n",
    "sequences_256_8_16\n",
    "sequences_256_16_64\n",
    "sequences_256_24_256\"\"\"\n",
    "\n",
    "patterns = list(map( pattern_filename, st ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1518, 16)\n",
      "../../patterns/sequences_64_24_64.json 0.3618421052631579\n",
      "(6126, 16)\n",
      "../../patterns/sequences_256_24_64.json 0.33931484502446985\n"
     ]
    }
   ],
   "source": [
    "for p in patterns:\n",
    "    cycle(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
